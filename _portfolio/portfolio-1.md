---
title: "PotterGPT: Character-level Transformer"
excerpt: "Minimal GPT-style transformer implemented in PyTorch<br/><img src='/images/image (1).png' width='500' height='300'>"
collection: portfolio
---

This project features a minimal character-level transformer built from scratch using PyTorch. It covers key components such as token embedding, multi-head self-attention, positional encoding, and autoregressive training on a simple bigram dataset.

GitHub Repository: [Character-level Transformer](https://github.com/JigyanshuPati/Character-level-Transformer)